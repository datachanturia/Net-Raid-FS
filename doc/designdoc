
პროექტის დასახელება: net raid file system

ავტორი: დავით ჭანტურია
ელ-ფოსტა: dchan13@freeuni.edu.ge

პროექტის შესრულებული პუნქტები:
	Raid 1 [20]
	Raid 5 [30]
	Cache [20]
	Designdoc [30]

დამატებითი შესრულებული პუნქტები:
	კონფიგურაციის ფაილი [-10]
	იერარქიული დირექტორიის სტრუქტურა [-10]
	ლოგირება [-10]

გადატვირთული სისტემური ბრძანებების ჩამონათვალი:
	open, read, write, release, rename, unlink, rmdir, mkdir, opendir, releasedir, create, getattr, chmod,readdir

პროგრამის მუშაობის პროცესის მოკლე სიტყვიერი აღწერა:
	make-თ ვაკომპილირებთ კოდს
	ვუშვებთ სერვერებს, სერვერები მუდმივი მოლოდინის რეჟიმში ელიან კლიენტის მხრიდან ქონექშენის გახნსა
	ვუშვებთ კლიენტს, კლიენტი იწყებს კონფიგ ფაილის პარსვას, ახარისხებს შესაბამის მონაცემებს შესაბამის სტრუქტურებში,
		წაკითხული მონაცემების საფუძველზე ვუერთდებით სერვერებს და ვამაუნთებთ ფიუზს მითითებულ დირექტორიაზე (დირექტორიებზე, თუ რამდენიმე გვხვდება და თითოეული დამაუნთების შემდეგ ვფორკავთ პროცესს), მითითებული რეიდის მიხედვით (1 ან 5).
	ახალ ტერმინალს ვხნით შევდივართ დამაუნთებულ დირექტორიაში და აწ უკვე გადატვირთული სისტემური ბრძანებებით ვიწყებთ
		ნეტ რეიდ ფაილ სისტემის გამოყენებას

პროგრამის გაშვების მაგალითზე:
	make
	./net_raid_server 127.0.0.1 10001 /home/vagrant/storage_dir1
	./net_raid_server 127.0.0.1 10002 /home/vagrant/storage_dir2
	./net_raid_server 127.0.0.1 11111 /home/vagrant/hotswap_dir
	./net_raid_client config_file

//-------------------------------------- კონფიგურაციის ფაილი [-10]
	კონფიგ ფაილის შედგენისას აუცილებელია დაცული იქნას კონკრეტული შეთანხმებული სტილი 
	(კონფიგ ფაილის მაგალით თან ახლავს პროექტს):
		1 ხაზზე გვხვდება "errorlog = " და მას მოსდევს უკვე არსებული ფაილის path
		2 ხაზზე გვხვდება "cache_size = " და "M"-ს შორის მოქცეული ქეშის ზომა (იგულისხმება მეგაბაიტებში)
		3 ხაზზე გვხვდება "cache_replacment = " და მოსდევს ალგორითმის დასახელება (თუ rlu არ წერია ქეში არ იმუშავებს)
		4 ხაზზე გვხვდება "timeout = " და მოსდევს თაიმაუთის დრო

		შემდეგ აუცილებლად პირველ სიმბოლოდ "\n"-ის შემცველი ხაზი გვხვდება, საიდანაც იწყება დისკების ჩამონათვალი,
		ყოველი შემდეგი წევრი ასევე გამოყოფილია ანალოგიურად პირველ სიმბოლოდ "\n"-ის შემცველი ხაზით:
			1. "diskname = " მოსდევს დისკის დასახელება
			2. "mountpoint = " მოსდევს არსებული ცარიელი მაუნთ დირექტორიის path-ი
			3. "raid = " მოსდევს 1 ან 5, დამოკიდებულია იმაზე თუ რომელი რეიდის გამოყენება სჭირდება უზერს
			4. "servers = " და მოსდევს სერვერებისა და პორტების ჩამონათვალი ", "-ებით გამოყოფილი ერთმანეთისგან
				სერვერები და პორტები კი გამოყოფილია ერთმანეთისგან ":"-სიმბოლოთი
			5. "hotswap = " ჰოთსვებ სერვერის სერვერ:პორტ წყვილი
		და ა.შ. n რაოდენობის ბლოკი

	საწყის ბლოკში წარმოდგენილი ინფორმაცია ინახება მოცემული ფორმატის სტრუქტურაში: 
		
		typedef struct {
			char* errorlog;
			char* cache_size;
			char* cache_replacment;
			int timeout;
		} basicInfo_t;

		თითოეული ელემენტის დასახელება შეესაბამება ქონფიგ ფაილის "key"-ს დასახელებას

	დანარჩენი ინფორმაცია ინახება შემდეგი ფორმატით:

		typedef struct {
			int logLen; 		//ბლოკების (დისკების) ჯამური რაოდენობა
			disk_t* disks; 		// მიმთითებელი დისკ სტრუქტურების მასივზე
		} diskList_t;

		typedef struct {
			char* diskname;			// დისკის დასახელება მაგ: STORAGE1
			char* mountpoint;		// მაუნთპოინტ დირექტორიის path
			int raid;				// მნიშვნელობა 1 ან 5
			myAddress_t* hotswap;	// აქ ინახება სერვერ ტიპის ინფორმაცია
			servList_t* servList;	// აქ კი სერვერ ტიპის სტრუქტურების მასივზე მისამართი
		} disk_t;

		typedef struct {
			char* ip;		// ip მისამართი სერვერის
			int port;		// სერვერზე პორტის ნომერი
		} myAddress_t;

		typedef struct {
			int logLen;				// სერვერების ჯამური რაოდენობა (ჰოთსვების გამოკლებით კონკრეტულ დისკზე)
			myAddress_t* servers;	// მიმთითებელი სერვერების მასივზე
		} servList_t;

//-------------------------------------- ლოგირება [-10]
	ლოგირება ხდება კონფიგ ფაილში მითითებულ შესაბამის ფაილში
	ლოგირების ფორმატი არის შემდეგი: მოვლენის მოხდენის დრო, დისკის დასახელება, დამატებითი გამოსატანი ინფორმაცია ->
	[Sun Jun 10 12:30:37 2018] STORAGE1 127.0.0.1:10001 open connection, ლოგირება ხდება დამაუნთებისას, ასევე
	ქონექშენის გახსნისას (იწერება როგორც წარმატებით ასევე წარუმატებლად დასრულების შესაბამისი მესიჯები).

	ასევე ლოგირებისას იწერება მომხდარი ერორები: strerror(errno)-თი ვიღებთ ერორ მესიჯს, შემდეგ კი მას ვწერთ ფაილში (ფორმატი კვლავ ზემოთ აღწერილი სახით)

//-------------------------------------- იერარქიული დირექტორიის სტრუქტურა [-10]
	იერარქიული დირექტორიის სტრუქტურა გააჩნია როგორც raid1-ს ასევე raid-5-ს. როდესაც mkdir ბრძანება გამოიძახება,
	raid1-ის შემთხვევაში ორივე სერვერზე იქმნება ეს დირექტორია სერვერის მხარეს ხოლო raid5-ის შემთხვევაში
	ასევე ანალოგიური n ცალი დირექტორია სერვერების მხარეს. ეს ფორმატი შესაძლებელს ხდის იერარქიული დირექტორიის 
	სტრუქტურის არსებობას. ჩვენ უკვე არსებულ იარარქიულ დირექტორიის სტრუქტურას ვიყენებთ.



//**********************************************************************************************\\
//-----------------------------------RAID--1--MIRRORING--[20]-----------------------------------\\
	
	ნებისმიერი სისტემური ბრძანების გამოძახება (getattr-ის readdir, და read-ის გარდა) ორივე სერვერზე.
	
	მაგალითად მოხდა mkdir-ის გამოძახება: პირველ გაგზავნაზე ვაგზავნით mkdir-ის მოთხოვნას,
	ასევე თან ვაყოლებთ დირექტორიის დასახელებას, ფლაგებს, და მოკლედ ნებისმიერ საჭირო ინფორმაციას.
	შემდეგ სერვერი გადაცემული ინფორმაციის საფუძველზე ცდილობს შეასრულოს ჩვენი ბრძანება და როდესაც
	დაასრულებს ბრძანებაზე მუშაობას აგზავნის ინფორმაციას თუ რა შედეგებით დასრულდა მოთხოვნილი ოპერაცია:
		აგზავნის სერვერის მხარეს დაბრუნებულ results და ასევე თუ შეცდომა მოხდა აგზავნის errno-ს.
	შემდეგ კლიენტის მხარე ხდება მიღებული შედეგების გაანალიზება:
		მაგალითად თუ რეზალტი -1-ია errno-ს დავსეტავთ კლიენტის მხარეს, დავაბრუნებთ მის უარყოფით მნიშვნელობას
		და ლოგში ჩავწერთ შესაბამის ერორ მესიჯს.

		თუ წარმატებით დასრულდა ოპერაცია, დავუსეტავთ თუ რამეზე დასასეტი იქნება მიღებული ინფოდან და დავაბრუნებთ
		შესაბამის არაუარყოფით მნიშვნელობას.
	(P.S) ზემოთ აღწერილია თითქმის ყველა სისქოლის მუშაობის ზოგადი ალგორითმი, რაც თითქმის ყველასთვის საერთოა.
	(P.P.S) მაგალითად mkdir-ის შემთხვევაში წარმატების შემთხვევაში ყველა (ჰოთსვეპის გარდა) სერვერზე შეიქმნება
		ბრძანებაში გადაცემული დირექტორია.

	განსაკუთრებულ მიდგომას საჭიროებდა შემდეგი სისტემური ბრძანებები: read, write, open
		read - წაკითხვის დროს ვკითხულობთ მხოლოდ და მხოლოდ 1 სერვერიდან, რადგან ვიცით რომ მეორე სერვერზეც
			ზუსტად იგივე ინფორმაცია წერია ფაილში რაც 1-ზე. წაკითხვისას ვაგზავნით წაკითხვის მოთხოვნას სერვერზე, 
			თან ვაყოლებთ წაკითხვისთვის აუცილებელ ინფოს, და ველოდებით პასუხს. თუ პასუხი არაუარყოფითია ველოდებით
			სერვერიდან 4096 ბაიტებად წამოსულ ჩანკებს და ამ ჩანკებიდან წაკითხულ ინფორმაცია ვწერთ მოცემულ ბუფერში.

		write - ჩაწერა ხდება stable storage ალგორითმით, ჯერ ერთ სერვერზე ვაგზავნით ჩაწერის მოთხოვნას, ვაგზავნით 
			4096 ბაიტებად ჩანკებს, შემდეგ კი ველოდებით დაბრუნებულ შედეგს. თუ შედეგი არაა უარყოფითი ანალოგიურს
			ვაკეთებთ მეორე სერვერზეც. ბოლოს კი ვიღებთ ორივე სერვერზე ჩაწერილ ერთსა და იმავე ინფორმაციას.

			ამ დროს სერვერის მხარეს SHA1-ალგორითმით ყოველ write-სისქოლზე ხდება მთლიანი ფაილის დაჰეშვა და ამ 
			ჰეშის xattr-ად მინიჭება ფაილზე.

		open - ფაილის ფახსნა, ერთ-ერთი ყველაზე შრომატევადო სისქოლია. ის გამოძახებისას ორივე სერვერზე აგზავნის
			ფაილის გახსნის მოთხოვნას, და ელოდება პასუხს. დაბრუნებულ პასუხში (სტანდარტულ რეზსა და ერრნო-სთან ერთად)
			გვიბრუნდება ფაილის ჰეშები, სულ 4 ცალი:
				სერვერის მხარეს სერვერი იღებს xattr-ს ფაილიდან, ასევე თვითონაც ჰეშავს ფაილს, და ორივე მონაცემს 
				აგზავნის.
			2 ჰეში ერთი სერვერიდან 2-მეორედან ჯამში 4. თუ 1 სერვერიდან გამოგზავნილი xattr-ჰეში არ დაემთხვა მეორე
			სერვერიდან გამოგზავნილ xattr-ჰეშს ანუ სადღაც ფაილი დაზიანდა. შემდეგ ვადარებთ xattr-ჰეში სად არ 
			ემთხვევა სერვერის მიერ დათვლილ ჰეშს და ვპოულობთ რომელ სერვერზე დაზიანდა ფაილი.

			შემდეგ იმ სერვერიდან სადაც დაუზიანებელი ფაილია ვკითხულობთ 4096 ბაიტს და ვწერთ მეორე სერვერზე
			სადაც ფაილი დაზიანდა. ინფორმაციას writes path-ში ვატანთ იმის შესახებ რომ ამჯერად გვინდა
			ჩაწერა მოხდეს 1 სერვერზე და არა ორივეზე. 

	გლობალური ცვლადები:
		int* allSFD; //სერვერების cfd-ების მასივი, რომლებთანაც ქონექშენი გვაქვს დამყარებული (ჰოთსვეპის გარდა)
		char** argvv; // აქ ვინახავთ დაპარსვის შემდეგ სტრუქტურებში დახარისხებულ ინფორმაციას (მაგ diskname-ს)
		struct cache_st* cache; //ქეშის სტრუქტურაც გლობალური გვაქვს, რათა მარტივად მივწვდეთ მას



//**********************************************************************************************\\
//-----------------------------------RAID--5--MIRRORING--[30]-----------------------------------\\
	დასაწყისშივე ავღნიშნავ, რომ raid-5-ში მუშაობს ყველაფერი read-სისქოლის გარდა.

	რეიდ 5-ის შემთხვევაში თუ გვაქვს 3 სერვერი, ეს ნიშნავს რომ მთავარინ ინფორმაცია იწერება
	2 სერვერზე. შესაბამისად სტრაიპების ზომა ავიღე სერვერების მიხედვით 4096/(n_serv - 1)
	ანუ 3 სერვერის შემთხვევაში 2048. ეს ვარიანტი ხელსაყრელია, რადგან read-write-ს შემთხვევაში
	ძირითადად 4096 ბაიტიანი ჩანკები გადმოგვეცემა ხოლმე და რათა 0-ები არ ვაგზავნოთ დანარჩენ სერვერებზე
	და ალბათობა გავზარდოთ იმისი, რომ ყველა სერვერი თანაბრად დაიტვირთება სასარგებლო ინფომაციის
	გატარებისას, 4096-ბაიტს ვანაწილებთ (ყველა სერვერ - 1) -ზე.

	რეიდ-5 ის შემთხვევაში არ ხდება სისქოლების გამოძახება მხოლოდ 2 სერვერზე, არამედ ყველა ჩამოთვლილ სერვერზე 
	(ჰოთსვეპის გარდა).

	მაგალითად unlink-ს გამოძახებისას ყველა სერვერზე მოხდება მითითებული ფაილის წაშლა.

	raid-5-ის შემთხვევაში განსაკუთრებული მიდგომა სჭირდებოდა read-ს და write-ს დანარჩენი სისქოლები თითქმის
	ანალოგიურია raid-1-ში იმპლემენტირებული სისქოლების. ვირტუალიზაციის დანარჩენი ასპექტები არ განსხვავდება.

	write - ჩაწერისას გადმოცემული offset-ის მიხედვით ვადგენთ თუ რომელი სერვერს უწევს დაქსორილი ელემენტების
		შენახვა. ამის გარკვევის შემდეგ, ვიცით რომ ჩანკი უნდა დავანაწევროთ n - 1 ნაწილად და მომდევნო n - 1
		სერვერზე ჩავწეროთ (ანუ ყველა სერვერზე უკვე არსებობს მოცემული ერთნაირი დასახელების ფაილები, ჩვენ კი
		რეალური ფაილის ნაწილებს ვინახავთ მათში ჩვენი ლოგიკით). ყოველი write-ს გამოძახებისას ხდემა მაქსიმუმ
		4096 ბაიტის ჩაწერა + მათი დაქსორილი მნიშვნელობის.
	read - write-ს ანალოგიურად ხდება წაკითხვა. პირველ რიგში ვიგებთ ოფსეტის მიხედვით რომელ სერვერზეა დაქსორილი
		მნიშვნელობა და მის მომდევნო n-1 სერვერიდან მოგვაქვს ინფო და შემდეგ კლიენტის მხარეს ვაწებებთ. ასევე
		read-ის შემთხვევაში ვკითხულობთ მაქსიმუმ 4096 ბაიტს თითო ჯერზე. 



//*********************************************************************************\\
//-----------------------------------Cache--[20]-----------------------------------\\
	ქეშირება - პროექტის ერთ-ერთი ყველაზე ნათელი ნაწილი, და გამოსადეგი სისტემისთვის.

	ქეში არის სტრუქტურების 1 მხარეს მიმართული ლინკდ ლისტი.

	typedef struct cache_t{
		char* name;				// ჩანკის path-ი ანუ თუ რომელი ფაილის ჩანკია
		size_t size;			// ჩანკის ჯამური ზომა
		off_t offset;			// ჩანკის ოფსეტის მნიშვნელობა
		void* chunk;			// ჩანკის მისამართი
		time_t lastUse;			// მოცემული ჩანკის ბოლოს გამოყენების დრო
		struct cache_t* next;	// ქეშის შემდეგი ელემენტის მისამართი
	} cache_t;

	typedef struct cache_st{
		size_t logLen;				// ქეშის მიმდინარე ზომა (ბაიტებში)
		size_t maxLen;				// ქეშის მაქსიმალური დასაშვები ზომა (ბაიტებში)
		struct cache_t* cacheStart;	// ვინახავთ ქეშის პირველი ელემენტის მისამართს
	} cache_st;

	ქეში მოცემული იმპლემენტაციით ნელ-ნელა იზრდება, და დავუშვათ მაქსიმუმ 1 024 000 000 ბაიტამდე ადის.
	
	ქეში მუშაობს rlu ალგორითმით, რაც გულისხმობს იმას, რომ თუ ქეში მაქსიმალურ ზომამდე მივიდა, 
		ვშლით ყველაზე ძველად გამოყენებულ ჩანკს (ან ჩანკებს) სანამ ახლისთვის არ დაგვრჩება ადგილი.
	ეს არის უბრალოდ ციკლი სადაც ვადარებთ გამოყენების მიხედვით დროებს და ასე ვპოულობთ სამიზნე ჩანკს.

	unlink- სისტემური ბრძანების გამოყენებისას ქეშიდან ავტომატურად ვშლით ყველა მონაცემს, რაც წასაშლელი
		ფაილიდან რაიმე ინფოს შეიცავდა.

	read - სისტემური ბრძანების გამოყენებისას ჯერ ვამოწმებთ გადმოცემული ოფსეტისა და ზომის მიხედვით,
		ჩვენს ლინკდ ლისტში რამე უბანი ხომ არ გვაქვს, (თუნდაც მოთხოვნილი ინფორმაციის ნაგლეჯი) აღმოჩენის
		შემთხვევაში ვაბრუნებთ ნაპოვნ უბანს. თუ ასეთი ვერ მოვძებნეთ, ტრადიციული მეთოდით სერვერიდან ვკითხულობთ
		სასურველ ინფორმაციას ფაილზე.

		წაკითხვის დადებითად დასრულების წინ, ვიღებთ წაკითხულ უბანს და ვამატებთ ქეშში ახალ ნოუდად.
/
//
///
////
გამოყენებული მასალები:
	https://github.com/libfuse/libfuse/blob/master/example/passthrough.c
	https://github.com/clibs/sha1
	"The Linux Programming Interface"
	http://en.wikipedia.org/wiki/C_date_and_time_functions
